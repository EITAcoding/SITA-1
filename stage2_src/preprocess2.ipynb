{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from models.neural import MultiHeadedAttention, PositionwiseFeedForward\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.linear1 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, mask_cls):\n",
    "        h = self.linear1(x).squeeze(-1)\n",
    "        sent_scores = self.sigmoid(h) * mask_cls.float()\n",
    "        return sent_scores\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout, dim, max_len=5000):\n",
    "        pe = torch.zeros(max_len, dim)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp((torch.arange(0, dim, 2, dtype=torch.float) *\n",
    "                              -(math.log(10000.0) / dim)))\n",
    "        pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.register_buffer('pe', pe)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, emb, step=None):\n",
    "        emb = emb * math.sqrt(self.dim)\n",
    "        if (step):\n",
    "            emb = emb + self.pe[:, step][:, None, :]\n",
    "\n",
    "        else:\n",
    "            emb = emb + self.pe[:, :emb.size(1)]\n",
    "        emb = self.dropout(emb)\n",
    "        return emb\n",
    "\n",
    "    def get_emb(self, emb):\n",
    "        return self.pe[:, :emb.size(1)]\n",
    "\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, d_ff, dropout):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "\n",
    "        self.self_attn = MultiHeadedAttention(\n",
    "            heads, d_model, dropout=dropout)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, iter, query, inputs, mask):\n",
    "        if (iter != 0):\n",
    "            input_norm = self.layer_norm(inputs)\n",
    "        else:\n",
    "            input_norm = inputs\n",
    "\n",
    "        mask = mask.unsqueeze(1)\n",
    "        context = self.self_attn(input_norm, input_norm, input_norm,\n",
    "                                 mask=mask)\n",
    "        out = self.dropout(context) + inputs\n",
    "        return self.feed_forward(out)\n",
    "\n",
    "\n",
    "class ExtTransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, heads, dropout, num_inter_layers=0):\n",
    "        super(ExtTransformerEncoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_inter_layers = num_inter_layers\n",
    "        self.pos_emb = PositionalEncoding(dropout, d_model)\n",
    "        self.transformer_inter = nn.ModuleList(\n",
    "            [TransformerEncoderLayer(d_model, heads, d_ff, dropout)\n",
    "             for _ in range(num_inter_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
    "        self.wo = nn.Linear(d_model, 1, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, top_vecs, mask):\n",
    "        \"\"\" See :obj:`EncoderBase.forward()`\"\"\"\n",
    "         \n",
    "        batch_size, n_sents = top_vecs.size(0), top_vecs.size(1)\n",
    "        pos_emb = self.pos_emb.pe[:, :n_sents]\n",
    "        x = top_vecs * mask[:, :, None].float()\n",
    "        x = x + pos_emb\n",
    "\n",
    "        for i in range(self.num_inter_layers):\n",
    "            x = self.transformer_inter[i](i, x, x, ~mask)  # all_sents * max_tokens * dim\n",
    "\n",
    "        x = self.layer_norm(x)\n",
    "        sent_scores = self.sigmoid(self.wo(x))\n",
    "        sent_scores = sent_scores.squeeze(-1) * mask.float()\n",
    "\n",
    "        return sent_scores\n",
    "\n",
    "\n",
    "class ExtImageTransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, heads, dropout, num_inter_layers=0):\n",
    "        super(ExtImageTransformerEncoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_inter_layers = num_inter_layers\n",
    "        self.pos_emb = PositionalEncoding(dropout, d_model)\n",
    "        self.transformer_inter = nn.ModuleList(\n",
    "            [TransformerEncoderLayer(d_model, heads, d_ff, dropout)\n",
    "             for _ in range(num_inter_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(d_model*2, eps=1e-6)\n",
    "        self.wo = nn.Linear(d_model*2, 1, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        #768\n",
    "        self.img_fn= nn.Sequential(\n",
    "            nn.Linear(2048,1024),\n",
    "            nn.Linear(1024,768))\n",
    "    def forward(self, top_vecs, mask,image_data):\n",
    "        \"\"\" See :obj:`EncoderBase.forward()`\"\"\"\n",
    "        \n",
    "        im_f = self.img_fn(image_data).unsqueeze(1).repeat(1,top_vecs.shape[1],1)\n",
    "        batch_size, n_sents = top_vecs.size(0), top_vecs.size(1)\n",
    "        pos_emb = self.pos_emb.pe[:, :n_sents]\n",
    "        x = top_vecs * mask[:, :, None].float()\n",
    "        x = x + pos_emb\n",
    "        \n",
    "        for i in range(self.num_inter_layers):\n",
    "            x = self.transformer_inter[i](i, x, x, ~mask)  # all_sents * max_tokens * dim\n",
    "        x = torch.cat([x,im_f],2)\n",
    "        x = self.layer_norm(x)\n",
    "        sent_scores = self.sigmoid(self.wo(x))\n",
    "        sent_scores = sent_scores.squeeze(-1) * mask.float()\n",
    "\n",
    "        return sent_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn([1,4,768])\n",
    "model = ExtImageTransformerEncoder(d_model=768,d_ff=2048,heads=8,dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
